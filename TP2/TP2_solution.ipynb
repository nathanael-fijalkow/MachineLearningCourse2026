{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d552b205",
   "metadata": {},
   "source": [
    "# Lab 2: Cross Validation with scikit-learn\n",
    "\n",
    "In this session, you will learn how to use cross validation to evaluate models in a robust way. You will use a simple dataset from scikit-learn and basic models.\n",
    "\n",
    "**Instructions:**\n",
    "- Fill in the code cells marked with 'To complete'.\n",
    "- Use only scikit-learn and pandas.\n",
    "- Try to understand what cross validation is and why it is useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57417aae",
   "metadata": {},
   "source": [
    "## 1. Load the dataset\n",
    "We will use the `wine` dataset from scikit-learn. This is a simple classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48954e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0051d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine(as_frame=True)\n",
    "data = wine.data\n",
    "target = wine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d8454",
   "metadata": {},
   "source": [
    "## 2. Explore the data\n",
    "Look at the first few rows and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1b53a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8fe23bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
       "count       178.000000  178.000000                    178.000000   178.000000  \n",
       "mean          5.058090    0.957449                      2.611685   746.893258  \n",
       "std           2.318286    0.228572                      0.709990   314.907474  \n",
       "min           1.280000    0.480000                      1.270000   278.000000  \n",
       "25%           3.220000    0.782500                      1.937500   500.500000  \n",
       "50%           4.690000    0.965000                      2.780000   673.500000  \n",
       "75%           6.200000    1.120000                      3.170000   985.000000  \n",
       "max          13.000000    1.710000                      4.000000  1680.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461cf95",
   "metadata": {},
   "source": [
    "## 3. Train/test split\n",
    "Before using cross validation, let's see what happens if we just split the data once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4d6b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e45b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.41\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "clf.fit(X_train, y_train)\n",
    "test_score = clf.score(X_test, y_test)\n",
    "print(f'Accuracy on test set: {test_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056fa74",
   "metadata": {},
   "source": [
    "## 4. Cross validation\n",
    "Now let's use cross validation to get a more robust estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "118156b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.38888889 0.38888889 0.38888889 0.4        0.42857143]\n",
      "Mean cross-validation score: 0.3990476190476191\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, data, target, cv=5)\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824dafba",
   "metadata": {},
   "source": [
    "## 5. Discussion\n",
    "- Why is cross validation better than a single train/test split?\n",
    "- What do you observe about the scores?\n",
    "\n",
    "**Sample answer:**\n",
    "- Cross validation gives a more reliable estimate of model performance because it averages over several splits, reducing the risk of a lucky or unlucky split.\n",
    "- The scores are all the same here because the DummyClassifier always predicts the most frequent class, but with a real model, you would see some variation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7889a2",
   "metadata": {},
   "source": [
    "## 6. Logistic Regression to the rescue\n",
    "\n",
    "Repeat the experiment with a LogisticRegression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79c99305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(max_iter=10000, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "test_score = clf.score(X_test, y_test)\n",
    "print(f'Accuracy on test set: {test_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "52ec65ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.97222222 0.91666667 0.91666667 1.         1.        ]\n",
      "Mean cross-validation score: 0.961111111111111\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, data, target, cv=5)\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b497330",
   "metadata": {},
   "source": [
    "## 7. Stratified Cross-Validation\n",
    "\n",
    "When dealing with classification problems, especially with imbalanced datasets (where some classes have significantly fewer samples than others), a simple K-Fold cross-validation might create folds where certain classes are underrepresented or entirely missing. This can lead to biased model evaluation.\n",
    "\n",
    "Stratified K-Fold cross-validation addresses this by ensuring that each fold has approximately the same percentage of samples of each target class as the complete set. Let's demonstrate this using the `breast_cancer` dataset, which has a binary target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21304096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original target distribution:\n",
      "target\n",
      "1    0.627417\n",
      "0    0.372583\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Scores with KFold (non-stratified):\n",
      "[0.96491228 0.98245614 0.95614035 0.95614035 1.        ]\n",
      "Mean accuracy: 0.972 +/- 0.017\n",
      "\n",
      "Scores with StratifiedKFold:\n",
      "[0.95614035 0.97368421 0.98245614 1.         0.98230088]\n",
      "Mean accuracy: 0.979 +/- 0.014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "breast_cancer = load_breast_cancer(as_frame=True)\n",
    "data_bc = breast_cancer.data\n",
    "target_bc = breast_cancer.target\n",
    "\n",
    "# Check target distribution\n",
    "print(\"Original target distribution:\")\n",
    "print(target_bc.value_counts(normalize=True))\n",
    "\n",
    "# Define a simple classifier\n",
    "clf_lr = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=0))\n",
    "\n",
    "print(\"\\nScores with KFold (non-stratified):\")\n",
    "cv_kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores_kfold = cross_val_score(clf_lr, data_bc, target_bc, cv=cv_kfold)\n",
    "print(scores_kfold)\n",
    "print(f\"Mean accuracy: {scores_kfold.mean():.3f} +/- {scores_kfold.std():.3f}\")\n",
    "\n",
    "print(\"\\nScores with StratifiedKFold:\")\n",
    "cv_stratified = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "scores_stratified = cross_val_score(clf_lr, data_bc, target_bc, cv=cv_stratified)\n",
    "print(scores_stratified)\n",
    "print(f\"Mean accuracy: {scores_stratified.mean():.3f} +/- {scores_stratified.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44463e3e",
   "metadata": {},
   "source": [
    "## 8. Effect of Preprocessing Steps (Scaling)\n",
    "\n",
    "Many machine learning algorithms perform better when numerical input variables are scaled to a standard range. This is especially true for algorithms that use distance calculations (like SVMs, K-Nearest Neighbors) or gradient descent optimization (like Logistic Regression, Neural Networks).\n",
    "\n",
    "Let's see the effect of `StandardScaler` on a `LogisticRegression` model using the `wine` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de41d042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores without scaling: [0.97222222 0.91666667 0.91666667 1.         1.        ]\n",
      "Mean accuracy without scaling: 0.961 +/- 0.038\n",
      "\n",
      "Scores with scaling: [0.97222222 0.97222222 1.         0.97142857 1.        ]\n",
      "Mean accuracy with scaling: 0.983 +/- 0.014\n"
     ]
    }
   ],
   "source": [
    "# Model without scaling\n",
    "clf_no_scale = LogisticRegression(max_iter=10000, random_state=0)\n",
    "scores_no_scale = cross_val_score(clf_no_scale, data, target, cv=5)\n",
    "print(\"Scores without scaling:\", scores_no_scale)\n",
    "print(f\"Mean accuracy without scaling: {scores_no_scale.mean():.3f} +/- {scores_no_scale.std():.3f}\")\n",
    "\n",
    "# Model with scaling using a pipeline\n",
    "clf_with_scale = make_pipeline(StandardScaler(), LogisticRegression(max_iter=10000, random_state=0))\n",
    "scores_with_scale = cross_val_score(clf_with_scale, data, target, cv=5)\n",
    "print(\"\\nScores with scaling:\", scores_with_scale)\n",
    "print(f\"Mean accuracy with scaling: {scores_with_scale.mean():.3f} +/- {scores_with_scale.std():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
