{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0fc1f2d",
   "metadata": {},
   "source": [
    "# Lab 2: Cross Validation with scikit-learn\n",
    "\n",
    "In this session, you will learn how to use cross validation to evaluate models in a robust way. You will use a simple dataset from scikit-learn and basic models.\n",
    "\n",
    "**Instructions:**\n",
    "- Fill in the code cells marked with 'To complete'.\n",
    "- Use only scikit-learn and pandas.\n",
    "- Try to understand what cross validation is and why it is useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57417aae",
   "metadata": {},
   "source": [
    "## 1. Load the dataset\n",
    "We will use the `wine` dataset from scikit-learn. This is a simple classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48954e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0051d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: Load the wine dataset as a pandas DataFrame\n",
    "# Assign the data to a variable 'data' and the target to 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d8454",
   "metadata": {},
   "source": [
    "## 2. Explore the data\n",
    "Look at the first few rows and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b53a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: Display the first 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe23bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: Display summary statistics for the features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461cf95",
   "metadata": {},
   "source": [
    "## 3. Train/test split\n",
    "Before using cross validation, let's see what happens if we just split the data once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: Split the data into train and test sets (test_size=0.3, random_state=0)\n",
    "# Use train_test_split from sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: Import a simple model (DummyClassifier with strategy='most_frequent')\n",
    "# Fit it on the training data and print the accuracy on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056fa74",
   "metadata": {},
   "source": [
    "## 4. Cross validation\n",
    "Now let's use cross validation to get a more robust estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118156b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: Use cross_val_score with 5-fold cross validation\n",
    "# Print the individual scores and their mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824dafba",
   "metadata": {},
   "source": [
    "## 5. Discussion\n",
    "- Why is cross validation better than a single train/test split?\n",
    "- What do you observe about the scores?\n",
    "\n",
    "*Write your answers below.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e070388",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "198ea3d3",
   "metadata": {},
   "source": [
    "## 6. Logistic Regression to the rescue\n",
    "\n",
    "Repeat the experiment with a LogisticRegression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f784e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: Implement Logistic Regression and evaluate it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242198db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: Use cross_val_score with 5-fold cross validation for Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa0234b",
   "metadata": {},
   "source": [
    "## 7. Stratified Cross-Validation\n",
    "\n",
    "When dealing with classification problems, especially with imbalanced datasets (where some classes have significantly fewer samples than others), a simple K-Fold cross-validation might create folds where certain classes are underrepresented or entirely missing. This can lead to biased model evaluation.\n",
    "\n",
    "Stratified K-Fold cross-validation addresses this by ensuring that each fold has approximately the same percentage of samples of each target class as the complete set. Let's demonstrate this using the `breast_cancer` dataset, which has a binary target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: compare KFold with StratifiedKFold\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "breast_cancer = load_breast_cancer(as_frame=True)\n",
    "data_bc = breast_cancer.data\n",
    "target_bc = breast_cancer.target\n",
    "\n",
    "# Check target distribution\n",
    "print(\"Original target distribution:\")\n",
    "print(target_bc.value_counts(normalize=True))\n",
    "\n",
    "# Define a simple classifier\n",
    "\n",
    "print(\"\\nScores with KFold (non-stratified):\")\n",
    "\n",
    "print(\"\\nScores with StratifiedKFold:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4622d867",
   "metadata": {},
   "source": [
    "## 8. Effect of Preprocessing Steps (Scaling)\n",
    "\n",
    "Many machine learning algorithms perform better when numerical input variables are scaled to a standard range. This is especially true for algorithms that use distance calculations (like SVMs, K-Nearest Neighbors) or gradient descent optimization (like Logistic Regression, Neural Networks).\n",
    "\n",
    "Let's see the effect of `StandardScaler` on a `LogisticRegression` model using the `wine` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete: Compare Logistic Regression performance with and without StandardScaler\n",
    "# Model without scaling\n",
    "\n",
    "# Model with scaling using a pipeline\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
