{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "784510d1",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction: Step-by-Step Data Wrangling for Classification\n",
    "\n",
    "This notebook walks through data wrangling and classification to predict survival on the Titanic. We'll:\n",
    "- Load train/test CSVs and inspect types/missing values\n",
    "- Coerce numeric types safely and clean strings\n",
    "- Impute missing values and encode categorical features\n",
    "- Train baseline and improved classifiers while handling class imbalance\n",
    "- Engineer features (e.g., `FamilySize`, `IsAlone`, `Title`, `FarePerPerson`)\n",
    "- Track metrics across cleaning experiments and generate test predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed9ce49",
   "metadata": {},
   "source": [
    "# Dataset Information\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "|----------|-----------|-----|\n",
    "| **survival** | Survival | 0 = No, 1 = Yes |\n",
    "| **pclass** | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| **sex** | Sex | M = Male, F = Female |\n",
    "| **age** | Age in years | Continuous |\n",
    "| **sibsp** | # of siblings / spouses aboard | Count |\n",
    "| **parch** | # of parents / children aboard | Count |\n",
    "| **ticket** | Ticket number | Text |\n",
    "| **fare** | Passenger fare | Continuous |\n",
    "| **cabin** | Cabin number | Text |\n",
    "| **embarked** | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12) Test shape: (418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports and data loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score, classification_report)\n",
    "\n",
    "# Paths\n",
    "TRAIN_PATH = 'train.csv'\n",
    "TEST_PATH = 'test.csv'\n",
    "\n",
    "# Load\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Separate target\n",
    "y = train['Survived']\n",
    "X = train.drop(columns=['Survived'])\n",
    "\n",
    "# Align columns between train features and test\n",
    "assert set(X.columns) == set(test.columns), 'Train features and test columns should match'\n",
    "print('Train shape:', train.shape, 'Test shape:', test.shape)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477c82b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "\n",
      "Missing values (train):\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "--- Test info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n",
      "None\n",
      "\n",
      "Missing values (test):\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "\n",
      "Class distribution in train (Survived):\n",
      "Survived\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Inspect dtypes and missing values\n",
    "print('--- Train info ---')\n",
    "print(train.info())\n",
    "print('\\nMissing values (train):\\n', train.isna().sum())\n",
    "print('\\n--- Test info ---')\n",
    "print(test.info())\n",
    "print('\\nMissing values (test):\\n', test.isna().sum())\n",
    "\n",
    "# Class distribution\n",
    "print('\\nClass distribution in train (Survived):')\n",
    "print(y.value_counts(normalize=True).rename('proportion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1306f63",
   "metadata": {},
   "source": [
    "# Data type coercion for numeric columns\n",
    "\n",
    "Real-world CSVs sometimes store numbers as strings with stray spaces. We'll safely coerce numeric types for `['Age','Fare','SibSp','Parch','Pclass']` by stripping whitespace and using `pd.to_numeric(errors='coerce')`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf47b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(nan), np.float64(3.14))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(\"3. 14 \", errors='coerce'), pd.to_numeric(\"    3.14 \", errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742af8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>2.308642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.526497</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.836071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.125</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age       Fare     SibSp     Parch    Pclass\n",
       "count      714.0      891.0     891.0     891.0     891.0\n",
       "mean   29.699118  32.204208  0.523008  0.381594  2.308642\n",
       "std    14.526497  49.693429  1.102743  0.806057  0.836071\n",
       "min         0.42        0.0       0.0       0.0       1.0\n",
       "25%       20.125     7.9104       0.0       0.0       2.0\n",
       "50%         28.0    14.4542       0.0       0.0       3.0\n",
       "75%         38.0       31.0       1.0       0.0       3.0\n",
       "max         80.0   512.3292       8.0       6.0       3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coerce numeric columns for both train/test\n",
    "numeric_cols = ['Age','Fare','SibSp','Parch','Pclass']\n",
    "def coerce_numeric(df, cols):\n",
    "    for col in cols:\n",
    "        # Convert to string, strip whitespace, then coerce to numeric\n",
    "        df[col] = pd.to_numeric(df[col].astype('string').str.strip(), errors='coerce')\n",
    "    return df\n",
    "\n",
    "X = coerce_numeric(X.copy(), numeric_cols)\n",
    "test = coerce_numeric(test.copy(), numeric_cols)\n",
    "\n",
    "X[numeric_cols].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba990b",
   "metadata": {},
   "source": [
    "# Basic imputations for missing values\n",
    "\n",
    "We'll impute missing values to enable modeling:\n",
    "- `Age`: median (optionally by `Pclass`/`Sex` later)\n",
    "- `Fare`: median by `Pclass`\n",
    "- `Embarked`: mode\n",
    "- Add `HasCabin` as 1 if `Cabin` present else 0; optionally drop `Cabin`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db826439",
   "metadata": {},
   "source": [
    ".mode() — most frequent value(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d76df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    20\n",
       " 1    30\n",
       " dtype: int64,\n",
       " 0    21\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 20, 20, 30, 30])\n",
    "t = pd.Series([1, 21, 21, 21, 3])\n",
    "s.mode(), t.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a1f0e8",
   "metadata": {},
   "source": [
    ".isna() — True where value is missing\n",
    "\n",
    ".notna() — True where value is not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc609979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    False\n",
       " 1     True\n",
       " 2    False\n",
       " dtype: bool,\n",
       " 0     True\n",
       " 1    False\n",
       " 2     True\n",
       " dtype: bool)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([10, None, 30])\n",
    "s.isna(),s.notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696606a",
   "metadata": {},
   "source": [
    ".any() — True if any element is True (often used after a boolean mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d02907a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([0, 0, 1])\n",
    "(s > 0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0e2c69",
   "metadata": {},
   "source": [
    " .fillna() — replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f89b8ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, None, 3])\n",
    "s.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50d41c",
   "metadata": {},
   "source": [
    "### `.loc` vs `.iloc`\n",
    "\n",
    "- `.loc` selects by **label** (index/column names), inclusive of endpoints when slicing.\n",
    "- `.iloc` selects by **position** (integer offsets), end-exclusive when slicing (like Python ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6279217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    name\n",
       " a  Alice\n",
       " b    Bob,\n",
       "    age\n",
       " a   25\n",
       " b   30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Cara'],\n",
    "    'age': [25, 30, 27]\n",
    "}, index=['a', 'b', 'c'])\n",
    "\n",
    "# loc: by label (inclusive slice)\n",
    "loc_rows = df.loc['a':'b', ['name']]\n",
    "\n",
    "# iloc: by position (end-exclusive slice)\n",
    "iloc_rows = df.iloc[0:2, 1:2]\n",
    "\n",
    "loc_rows, iloc_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f90ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple cleaned copies for a baseline\n",
    "X_clean = X.copy()\n",
    "test_clean = test.copy()\n",
    "\n",
    "# Embarked mode (on full train to avoid leakage within split)\n",
    "embarked_mode = X_clean['Embarked'].mode().iloc[0] if X_clean['Embarked'].notna().any() else 'S'\n",
    "X_clean['Embarked'] = X_clean['Embarked'].fillna(embarked_mode)\n",
    "test_clean['Embarked'] = test_clean['Embarked'].fillna(embarked_mode)\n",
    "\n",
    "# Fare median by Pclass\n",
    "fare_by_pclass = X_clean.groupby('Pclass')['Fare'].median()\n",
    "def fill_fare(row):\n",
    "    if pd.isna(row['Fare']):\n",
    "        return fare_by_pclass.get(row['Pclass'], X_clean['Fare'].median())\n",
    "    return row['Fare']\n",
    "X_clean['Fare'] = X_clean.apply(fill_fare, axis=1)\n",
    "test_clean['Fare'] = test_clean.apply(fill_fare, axis=1)\n",
    "\n",
    "# Age median\n",
    "age_median = X_clean['Age'].median()\n",
    "X_clean['Age'] = X_clean['Age'].fillna(age_median)\n",
    "test_clean['Age'] = test_clean['Age'].fillna(age_median)\n",
    "\n",
    "# HasCabin feature\n",
    "X_clean['HasCabin'] = (X_clean['Cabin'].notna()).astype(int) if 'Cabin' in X_clean.columns else 0\n",
    "test_clean['HasCabin'] = (test_clean['Cabin'].notna()).astype(int) if 'Cabin' in test_clean.columns else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd29292",
   "metadata": {},
   "source": [
    "# Categorical encoding\n",
    "\n",
    "We treat `Pclass` as categorical along with `Sex` and `Embarked`. Numeric features are `Age`, `Fare`, `SibSp`, `Parch`. We'll use `OneHotEncoder(handle_unknown='ignore')` for categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d0175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8114478114478114\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['Sex','Embarked','Pclass']\n",
    "numeric_features = ['Age','Fare','SibSp','Parch'] + (['HasCabin'] if 'HasCabin' in X_clean.columns else [])\n",
    "\n",
    "# Preprocess: impute numeric (median), scale; one-hot encode categorical\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocess_v1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    " )\n",
    "\n",
    "clf_lr = Pipeline(steps=[\n",
    "    ('preprocess', preprocess_v1),\n",
    "    ('model', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit on full training data\n",
    "clf_lr.fit(X_clean, y)\n",
    "y_pred_train = clf_lr.predict(X_clean)\n",
    "\n",
    "print('Training Accuracy:', accuracy_score(y, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae1b96",
   "metadata": {},
   "source": [
    "# Evaluation metric\n",
    "\n",
    "We'll use accuracy to evaluate model performance:\n",
    "- Accuracy: $\\text{Accuracy} = \\frac{TP+TN}{TP+TN+FP+FN}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2466a8a",
   "metadata": {},
   "source": [
    "# Address class imbalance\n",
    "\n",
    "Titanic labels are not perfectly balanced. We’ll inspect the ratio and refit with `class_weight='balanced'` to weight minority class more during training, and compare metrics including balanced accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c92f1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (balanced): 0.7991021324354658\n"
     ]
    }
   ],
   "source": [
    "# Refit LogisticRegression with class_weight='balanced'\n",
    "clf_lr_bal = Pipeline(steps=[\n",
    "    ('preprocess', preprocess_v1),\n",
    "    ('model', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Fit on full training data\n",
    "clf_lr_bal.fit(X_clean, y)\n",
    "y_pred_train_bal = clf_lr_bal.predict(X_clean)\n",
    "\n",
    "print('Training Accuracy (balanced):', accuracy_score(y, y_pred_train_bal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e5f91",
   "metadata": {},
   "source": [
    "## How to properly compare the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ae26c",
   "metadata": {},
   "source": [
    "Here are the mathematical formulas for precision, recall, and F1-score:\n",
    "\n",
    "**Precision**: Measures how many of the predicted positives are actually positive.\n",
    "\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**Recall** (Sensitivity): Measures how many of the actual positives were correctly identified.\n",
    "\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**F1-Score**: Harmonic mean of precision and recall, balancing both metrics.\n",
    "\n",
    "$$\\text{F1-score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} = \\frac{2 \\times TP}{2 \\times TP + FP + FN}$$\n",
    "\n",
    "Where:\n",
    "- **TP** (True Positives): Correctly predicted positive cases\n",
    "- **FP** (False Positives): Incorrectly predicted as positive (Type I error)\n",
    "- **FN** (False Negatives): Incorrectly predicted as negative (Type II error)\n",
    "- **TN** (True Negatives): Correctly predicted negative cases\n",
    "\n",
    "For the Titanic example:\n",
    "- **Precision for \"Survived\"**: Of all passengers we predicted survived, what percentage actually survived?\n",
    "- **Recall for \"Survived\"**: Of all passengers who actually survived, what percentage did we correctly predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eff00dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Without class_weight='balanced' ===\n",
      "Accuracy: 0.8114\n",
      "Balanced Accuracy: 0.7946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.83      0.87      0.85       549\n",
      "    Survived       0.77      0.72      0.75       342\n",
      "\n",
      "    accuracy                           0.81       891\n",
      "   macro avg       0.80      0.79      0.80       891\n",
      "weighted avg       0.81      0.81      0.81       891\n",
      "\n",
      "\n",
      "=== With class_weight='balanced' ===\n",
      "Accuracy: 0.7991\n",
      "Balanced Accuracy: 0.7940\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Survived       0.85      0.82      0.83       549\n",
      "    Survived       0.72      0.77      0.75       342\n",
      "\n",
      "    accuracy                           0.80       891\n",
      "   macro avg       0.79      0.79      0.79       891\n",
      "weighted avg       0.80      0.80      0.80       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare both models\n",
    "print(\"=== Without class_weight='balanced' ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred_train):.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y, y_pred_train):.4f}\")\n",
    "print(classification_report(y, y_pred_train, target_names=['Not Survived', 'Survived']))\n",
    "\n",
    "print(\"\\n=== With class_weight='balanced' ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred_train_bal):.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y, y_pred_train_bal):.4f}\")\n",
    "print(classification_report(y, y_pred_train_bal, target_names=['Not Survived', 'Survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29e1a3",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "We’ll add domain-inspired features:\n",
    "- `FamilySize = SibSp + Parch + 1`\n",
    "- `IsAlone = (FamilySize == 1)`\n",
    "- `Title` extracted from `Name`\n",
    "- `FarePerPerson = Fare / FamilySize`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b4bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "      <th>FarePerPerson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>3.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>35.64165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>7.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>26.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FamilySize  IsAlone Title  FarePerPerson\n",
       "0           2        0    Mr          3.625\n",
       "1           2        0   Mrs       35.64165\n",
       "2           1        1  Miss          7.925\n",
       "3           2        0   Mrs          26.55\n",
       "4           1        1    Mr           8.05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    # Family features\n",
    "    df['FamilySize'] = df['SibSp'].fillna(0) + df['Parch'].fillna(0) + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    # Title from Name\n",
    "    if 'Name' in df.columns:\n",
    "        df['Title'] = df['Name'].str.extract(r',\\s*([^\\.]+)\\.')\n",
    "        # Rare title grouping\n",
    "        title_counts = df['Title'].value_counts()\n",
    "        rare = title_counts[title_counts < 10].index\n",
    "        df['Title'] = df['Title'].replace(rare, 'Rare')\n",
    "    else:\n",
    "        df['Title'] = 'Unknown'\n",
    "    # Fare per person\n",
    "    df['FarePerPerson'] = (df['Fare'] / df['FamilySize']).replace([np.inf, -np.inf], np.nan)\n",
    "    return df\n",
    "\n",
    "X_fe = add_features(X_clean)\n",
    "test_fe = add_features(test_clean)\n",
    "X_fe[['FamilySize','IsAlone','Title','FarePerPerson']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a33a53",
   "metadata": {},
   "source": [
    "# Transformations and outlier handling\n",
    "\n",
    "To reduce skew, we’ll apply log transforms:\n",
    "- `FareLog = log1p(Fare)`\n",
    "- `FarePerPersonLog = log1p(FarePerPerson)`\n",
    "Optionally, bin `Age` into quantiles for robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb00b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>FareLog</th>\n",
       "      <th>FarePerPerson</th>\n",
       "      <th>FarePerPersonLog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.204208</td>\n",
       "      <td>2.962246</td>\n",
       "      <td>19.916375</td>\n",
       "      <td>2.565012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.969048</td>\n",
       "      <td>35.841257</td>\n",
       "      <td>0.85768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.910400</td>\n",
       "      <td>2.187218</td>\n",
       "      <td>7.25</td>\n",
       "      <td>2.110213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.454200</td>\n",
       "      <td>2.737881</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.230014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>3.205453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>512.329200</td>\n",
       "      <td>6.240917</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>6.240917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fare     FareLog  FarePerPerson  FarePerPersonLog\n",
       "count  891.000000  891.000000          891.0             891.0\n",
       "mean    32.204208    2.962246      19.916375          2.565012\n",
       "std     49.693429    0.969048      35.841257           0.85768\n",
       "min      0.000000    0.000000            0.0               0.0\n",
       "25%      7.910400    2.187218           7.25          2.110213\n",
       "50%     14.454200    2.737881            8.3          2.230014\n",
       "75%     31.000000    3.465736      23.666667          3.205453\n",
       "max    512.329200    6.240917       512.3292          6.240917"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_transforms(df):\n",
    "    df = df.copy()\n",
    "    df['FareLog'] = np.log1p(df['Fare'])\n",
    "    if 'FarePerPerson' in df.columns:\n",
    "        df['FarePerPersonLog'] = np.log1p(df['FarePerPerson'].fillna(0))\n",
    "    return df\n",
    "\n",
    "X_tx = add_transforms(X_fe)\n",
    "test_tx = add_transforms(test_fe)\n",
    "X_tx[['Fare','FareLog','FarePerPerson','FarePerPersonLog']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6154e",
   "metadata": {},
   "source": [
    "# Reproducible Pipeline with ColumnTransformer\n",
    "\n",
    "We’ll build a reusable pipeline that applies feature engineering (via `FunctionTransformer`), imputations, encoding, scaling, and `LogisticRegression(class_weight='balanced')`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fe25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (LR with FE): 0.8316498316498316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def feature_engineer(df):\n",
    "    return add_transforms(add_features(df))\n",
    "\n",
    "feature_step = FunctionTransformer(feature_engineer, validate=False)\n",
    "\n",
    "# Expanded feature sets after FE\n",
    "cat_features_fe = ['Sex','Embarked','Pclass','Title']\n",
    "num_features_fe = ['Age','Fare','SibSp','Parch','FamilySize','IsAlone','FarePerPerson','FareLog','FarePerPersonLog'] + (['HasCabin'] if 'HasCabin' in X_tx.columns else [])\n",
    "\n",
    "numeric_tx = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_tx = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocess_fe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_tx, num_features_fe),\n",
    "        ('cat', categorical_tx, cat_features_fe)\n",
    "    ]\n",
    " )\n",
    "\n",
    "pipe_lr_bal_fe = Pipeline(steps=[\n",
    "    ('features', feature_step),\n",
    "    ('preprocess', preprocess_fe),\n",
    "    ('model', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Fit on full training data\n",
    "pipe_lr_bal_fe.fit(X_clean, y)\n",
    "y_pred_lr_train = pipe_lr_bal_fe.predict(X_clean)\n",
    "\n",
    "print('Training Accuracy (LR with FE):', accuracy_score(y, y_pred_lr_train))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
